import pandas as pd
import numpy as np
import sys
from pathlib import Path
from io import StringIO
from datetime import datetime

# ===================================================================
# æ—¥èªŒç³»çµ±è¨­å®š
# ===================================================================
# å»ºç«‹ log æª”æ¡ˆè·¯å¾‘
output_model_dir = Path("data/ML_boxoffice/phase4_models/M1")
output_model_dir.mkdir(parents=True, exist_ok=True)

timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
log_file = output_model_dir / f"training_log_{timestamp}.txt"

# å»ºç«‹ log ç·©è¡å€
log_buffer = StringIO()


# å»ºç«‹è‡ªè¨‚çš„ print å‡½æ•¸,åŒæ™‚è¼¸å‡ºåˆ°çµ‚ç«¯æ©Ÿå’Œ log
class Logger:
    def __init__(self, log_buffer):
        self.terminal = sys.stdout
        self.log = log_buffer

    def write(self, message):
        self.terminal.write(message)
        self.log.write(message)

    def flush(self):
        self.terminal.flush()


# é‡å®šå‘ stdout
sys.stdout = Logger(log_buffer)

print("=" * 60)
print(f"ğŸš€ æ¨¡å‹è¨“ç·´é–‹å§‹: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
print("=" * 60)


# ===================================================================
# è³‡æ–™é è™•ç†
# ===================================================================
# === è¨­å®šè·¯å¾‘ ===
output_prepare_dir = Path("data/ML_boxoffice/phase3_prepare/M1")
output_model_dir = Path("data/ML_boxoffice/phase4_models/M1")
output_prepare_dir.mkdir(parents=True, exist_ok=True)

# === 1. è®€å–è³‡æ–™ ===
df = pd.read_csv(
    "data/ML_boxoffice/phase2_features/with_market/features_market_2025-11-07.csv"
)  # æ›¿æ›æˆä½ çš„æª”æ¡ˆè·¯å¾‘


# === 2. ç¯©é¸è³‡æ–™ ===
# åªä¿ç•™é¦–è¼ªè³‡æ–™
df = df[df["round_idx"] == 1].copy()
# åªä¿ç•™æœ‰æ´»èºé€±æ¬¡çš„è³‡æ–™
df = df[df["current_week_active_idx"].notna()]
# å¿…é ˆåŒæ™‚æœ‰ week_1 å’Œ week_2 çš„è³‡æ–™,ä¸”éƒ½ä¸ç‚º 0
df = df[
    (df["boxoffice_week_1"].notna())
    & (df["boxoffice_week_1"] > 0)
    & (df["boxoffice_week_2"].notna())
    & (df["boxoffice_week_2"] > 0)
]
print(f"ç¯©é¸å¾Œè³‡æ–™ç­†æ•¸: {len(df)}")


# === 3. æœˆä»½é€±æœŸæ€§ç·¨ç¢¼ ===
df["release_month_sin"] = np.sin(2 * np.pi * df["release_month"] / 12)
df["release_month_cos"] = np.cos(2 * np.pi * df["release_month"] / 12)


# === 4. åˆªé™¤ä¸éœ€è¦çš„æ¬„ä½ ===
# å®šç¾©è¦åˆªé™¤çš„æ¬„ä½
drop_columns = [
    # è³‡æ–™æ´©æ¼
    "tickets",
    "theater_count",  # amount è¦ç•™åˆ°æœ€å¾Œæ‰åˆª
    # ä¸éœ€è¦çš„æ™‚é–“è³‡è¨Š
    "official_release_date",
    "week_range",
    "current_week_real_idx",
    # è·¨è¼ªç´¯ç©
    "boxoffice_cumsum",
    "boxoffice_round1_cumsum",
    "boxoffice_current_round_cumsum",  # â† æª¢æŸ¥é€™å€‹
    "audience_cumsum",
    "audience_round1_cumsum",
    "audience_current_round_cumsum",  # â† æª¢æŸ¥é€™å€‹
    "rounds_cumsum",
    # å•é¡Œæ¬„ä½
    "ticket_price_avg_current",
    # åˆ†é¡æ¬„ä½ (æ™‚é–“æœ‰é™å…ˆåˆªé™¤)
    "region",
    "publisher",
    # å·²ç·¨ç¢¼çš„åŸå§‹æ¬„ä½
    "release_month",
]

df = df.drop(columns=drop_columns)


# === 5. æª¢æŸ¥ç¼ºå¤±å€¼ ===
print("\n=== ç¼ºå¤±å€¼æª¢æŸ¥ ===")
print(df.isnull().sum()[df.isnull().sum() > 0])


# === 6. å­˜æª”: å®Œæ•´è³‡æ–™ (å« amount å’Œ gov_id) ===
df.to_csv(output_prepare_dir / "preprocessed_full.csv", index=False, encoding="utf-8-sig")
print(f"\nâœ… å·²å­˜æª”: {output_prepare_dir / 'preprocessed_full.csv'}")
print(f"   æ¬„ä½æ•¸: {len(df.columns)}")
print(f"   è³‡æ–™ç­†æ•¸: {len(df)}")


# === 7. é¡¯ç¤ºæœ€çµ‚æ¬„ä½ ===
print("\n=== æœ€çµ‚æ¬„ä½æ¸…å–® ===")
for i, col in enumerate(df.columns, 1):
    print(f"{i:2d}. {col}")


# === 8. å­˜æª”: è¨“ç·´ç”¨ç‰¹å¾µ (ç§»é™¤ amountï¼Œä¿ç•™ gov_id ç”¨æ–¼åˆ†çµ„) ===
feature_cols = [col for col in df.columns if col != "amount"]
df_features = df[feature_cols]
df_features.to_csv(
    output_prepare_dir / "preprocessed_features.csv", index=False, encoding="utf-8-sig"
)
print(f"\nâœ… å·²å­˜æª”: {output_prepare_dir / 'preprocessed_features.csv'}")


# === 9. å­˜æª”: ç›®æ¨™è®Šæ•¸ ===
df[["gov_id", "amount"]].to_csv(
    output_prepare_dir / "preprocessed_target.csv", index=False, encoding="utf-8-sig"
)
print(f"âœ… å·²å­˜æª”: {output_prepare_dir / 'preprocessed_target.csv'}")


# === 10. çµ±è¨ˆæ‘˜è¦ ===
print("\n=== è³‡æ–™æ‘˜è¦ ===")
print(df[["amount", "boxoffice_week_1", "current_week_active_idx"]].describe())


# ===================================================================
# è¨“ç·´æ¨¡å‹
# ===================================================================
# === 11. åˆ†é›¢ç‰¹å¾µèˆ‡ç›®æ¨™ ===
X = df.drop(columns=["amount"])
y = df["amount"]

print(f"\nç‰¹å¾µçŸ©é™£ X: {X.shape}")
print(f"ç›®æ¨™è®Šæ•¸ y: {y.shape}")

print("\n" + "=" * 50)
print("ğŸ” ç‰¹å¾µèˆ‡ç›®æ¨™ç›¸é—œæ€§ (Top 10)")
print("=" * 50)

correlation = pd.DataFrame(
    {
        "feature": X.drop(columns=["gov_id"]).columns,
        "correlation": X.drop(columns=["gov_id"]).corrwith(y),
    }
).sort_values("correlation", key=abs, ascending=False)

print(correlation.head(10).to_string(index=False))


# === 12. Group-based åˆ‡åˆ†è³‡æ–™é›† ===
from sklearn.model_selection import GroupShuffleSplit

# ç¢ºä¿åŒä¸€éƒ¨é›»å½±çš„æ‰€æœ‰é€±æ¬¡è³‡æ–™ä¸æœƒåŒæ™‚å‡ºç¾åœ¨è¨“ç·´/æ¸¬è©¦é›†
splitter = GroupShuffleSplit(test_size=0.2, n_splits=1, random_state=42)
train_idx, test_idx = next(splitter.split(X, y, groups=X["gov_id"]))

X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]
y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]

print(f"\nè¨“ç·´é›†: {len(X_train)} ç­† ({len(X_train['gov_id'].unique())} éƒ¨é›»å½±)")
print(f"æ¸¬è©¦é›†: {len(X_test)} ç­† ({len(X_test['gov_id'].unique())} éƒ¨é›»å½±)")


# === 13. ç§»é™¤ gov_id (åªç”¨æ–¼åˆ†çµ„,ä¸åƒèˆ‡è¨“ç·´) ===
X_train_model = X_train.drop(columns=["gov_id"])
X_test_model = X_test.drop(columns=["gov_id"])

print(f"\næ¨¡å‹è¨“ç·´ç‰¹å¾µæ•¸: {X_train_model.shape[1]}")


# === 13.5 æª¢æŸ¥ç¼ºå¤±å€¼ ===
print("\n" + "=" * 50)
print("ğŸ” è¨“ç·´é›†ç¼ºå¤±å€¼æª¢æŸ¥")
print("=" * 50)

missing_train = X_train_model.isnull().sum()
missing_train = missing_train[missing_train > 0].sort_values(ascending=False)

if len(missing_train) > 0:
    print("âš ï¸ ç™¼ç¾ç¼ºå¤±å€¼:")
    print(missing_train)
    print(f"\nç¸½ç¼ºå¤±ç­†æ•¸: {X_train_model.isnull().any(axis=1).sum()}/{len(X_train_model)}")
else:
    print("âœ… ç„¡ç¼ºå¤±å€¼")


# === 14. è¨“ç·´åŸºæº–æ¨¡å‹: Linear Regression ===
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

print("\n" + "=" * 50)
print("ğŸ”µ æ¨¡å‹ 1: Linear Regression")
print("=" * 50)

lr_model = LinearRegression()
lr_model.fit(X_train_model, y_train)

y_pred_lr = lr_model.predict(X_test_model)

print(f"MAE:  {mean_absolute_error(y_test, y_pred_lr):,.0f}")
print(f"RMSE: {np.sqrt(mean_squared_error(y_test, y_pred_lr)):,.0f}")
print(f"RÂ²:   {r2_score(y_test, y_pred_lr):.4f}")


# === 15. è¨“ç·´é€²éšæ¨¡å‹: LightGBM ===
import lightgbm as lgb

print("\n" + "=" * 50)
print("ğŸŸ¢ æ¨¡å‹ 2: LightGBM")
print("=" * 50)

lgb_model = lgb.LGBMRegressor(
    n_estimators=100,
    learning_rate=0.05,
    max_depth=5,
    random_state=42,
    verbose=-1,  # é—œé–‰è¨“ç·´éç¨‹è¼¸å‡º
)

lgb_model.fit(X_train_model, y_train)

y_pred_lgb = lgb_model.predict(X_test_model)

print(f"MAE:  {mean_absolute_error(y_test, y_pred_lgb):,.0f}")
print(f"RMSE: {np.sqrt(mean_squared_error(y_test, y_pred_lgb)):,.0f}")
print(f"RÂ²:   {r2_score(y_test, y_pred_lgb):.4f}")


# ===================================================================
# æ´å¯Ÿæ¨¡å‹åˆ†æçµæœ
# ===================================================================
# === 16. ç‰¹å¾µé‡è¦æ€§åˆ†æ ===
print("\n" + "=" * 50)
print("ğŸ“Š Top 10 é‡è¦ç‰¹å¾µ (LightGBM)")
print("=" * 50)

feature_importance = pd.DataFrame(
    {"feature": X_train_model.columns, "importance": lgb_model.feature_importances_}
).sort_values("importance", ascending=False)

print(feature_importance.head(10).to_string(index=False))

# å­˜æª”ç‰¹å¾µé‡è¦æ€§
feature_importance.to_csv(
    output_model_dir / "feature_importance.csv", index=False, encoding="utf-8-sig"
)
print(f"\nâœ… ç‰¹å¾µé‡è¦æ€§å·²å­˜æª”: {output_model_dir / 'feature_importance.csv'}")


# === 17. è¦–è¦ºåŒ–: é æ¸¬ vs å¯¦éš› ===
import matplotlib.pyplot as plt

plt.rcParams["font.sans-serif"] = ["Microsoft JhengHei"]  # ä¸­æ–‡å­—å‹
plt.rcParams["axes.unicode_minus"] = False

fig, axes = plt.subplots(1, 2, figsize=(14, 5))

# Linear Regression
axes[0].scatter(y_test, y_pred_lr, alpha=0.5, s=10)
axes[0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], "r--", lw=2)
axes[0].set_xlabel("å¯¦éš›ç¥¨æˆ¿")
axes[0].set_ylabel("é æ¸¬ç¥¨æˆ¿")
axes[0].set_title(f"Linear Regression (RÂ²={r2_score(y_test, y_pred_lr):.3f})")
axes[0].grid(True, alpha=0.3)

# LightGBM
axes[1].scatter(y_test, y_pred_lgb, alpha=0.5, s=10)
axes[1].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], "r--", lw=2)
axes[1].set_xlabel("å¯¦éš›ç¥¨æˆ¿")
axes[1].set_ylabel("é æ¸¬ç¥¨æˆ¿")
axes[1].set_title(f"LightGBM (RÂ²={r2_score(y_test, y_pred_lgb):.3f})")
axes[1].grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig(output_model_dir / "prediction_comparison.png", dpi=150, bbox_inches="tight")
print(f"âœ… é æ¸¬çµæœåœ–å·²å­˜æª”: {output_model_dir / 'prediction_comparison.png'}")
plt.show()


# ===================================================================
# å„²å­˜æ¨¡å‹èˆ‡åˆ†æçµæœ
# ===================================================================
# === 18. å„²å­˜æ¨¡å‹ ===
import joblib

joblib.dump(lr_model, output_model_dir / "model_linear_regression.pkl")
joblib.dump(lgb_model, output_model_dir / "model_lightgbm.pkl")
print(f"\nâœ… æ¨¡å‹å·²å­˜æª”:")
print(f"   - {output_model_dir / 'model_linear_regression.pkl'}")
print(f"   - {output_model_dir / 'model_lightgbm.pkl'}")


# === 19. å„²å­˜æ¸¬è©¦é›†é æ¸¬çµæœ ===
results = pd.DataFrame(
    {
        "gov_id": X_test["gov_id"].values,
        "actual": y_test.values,
        "pred_lr": y_pred_lr,
        "pred_lgb": y_pred_lgb,
        "error_lr": y_test.values - y_pred_lr,
        "error_lgb": y_test.values - y_pred_lgb,
    }
)

results.to_csv(output_model_dir / "test_predictions.csv", index=False, encoding="utf-8-sig")
print(f"âœ… æ¸¬è©¦é›†é æ¸¬çµæœå·²å­˜æª”: {output_model_dir / 'test_predictions.csv'}")


# === 20. ç´€éŒ„æœ¬æ¬¡åŸ·è¡Œéç¨‹log ===
print("\n" + "=" * 60)
print(f"âœ… è¨“ç·´å®Œæˆ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
print("=" * 60)

# å¯«å…¥ log æª”æ¡ˆ
sys.stdout = sys.stdout.terminal  # æ¢å¾©æ­£å¸¸çš„ stdout
with open(log_file, "w", encoding="utf-8") as f:
    f.write(log_buffer.getvalue())

print(f"\nâœ… è¨“ç·´ç´€éŒ„å·²å­˜æª”: {log_file}")
print("\nğŸ‰ è¨“ç·´å®Œæˆ!")

# ===================================================================
#                                 END
# ===================================================================

# ===================================================================
# è£œå……èªªæ˜
# ===================================================================
"""
## ğŸ“¦ æœ€çµ‚æœƒç”¢ç”Ÿçš„æª”æ¡ˆ
```
data/ML_boxoffice/phase3_prepare/
â”œâ”€â”€ preprocessed_full.csv           # å®Œæ•´é è™•ç†è³‡æ–™
â”œâ”€â”€ preprocessed_features.csv       # ç‰¹å¾µçŸ©é™£ (X)
â”œâ”€â”€ preprocessed_target.csv         # ç›®æ¨™è®Šæ•¸ (y)
â”œâ”€â”€ feature_importance.csv          # ç‰¹å¾µé‡è¦æ€§æ’å
â”œâ”€â”€ prediction_comparison.png       # é æ¸¬ vs å¯¦éš›æ•£ä½ˆåœ–
â”œâ”€â”€ test_predictions.csv            # æ¸¬è©¦é›†è©³ç´°é æ¸¬çµæœ
â”œâ”€â”€ model_linear_regression.pkl     # å·²è¨“ç·´çš„ LR æ¨¡å‹
â””â”€â”€ model_lightgbm.pkl              # å·²è¨“ç·´çš„ LightGBM æ¨¡å‹
"""
