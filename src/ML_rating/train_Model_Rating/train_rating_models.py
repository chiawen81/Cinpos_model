# uv run src\ML_rating\train_Model_Rating\train_rating_models.py
# =====================================================
# ğŸ¬ IMDb Rating é›™æ¨¡å‹è¨“ç·´ (LightGBM + DecisionTree)
# =====================================================
import pandas as pd
import numpy as np
import sys
from pathlib import Path
from io import StringIO
from datetime import datetime
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.ensemble import RandomForestRegressor  # âœ… åŠ å…¥é€™è¡Œ
import lightgbm as lgb
import matplotlib.pyplot as plt
import joblib

# =====================================================
# ğŸ“ è¼¸å‡ºè³‡æ–™å¤¾è¨­å®š
# =====================================================
output_dir = Path("data/ML_rating/2type_rating_models_PART3")
output_dir.mkdir(parents=True, exist_ok=True)

timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
log_file = output_dir / f"training_log_{timestamp}.txt"
log_buffer = StringIO()

# =====================================================
# ğŸ§¾ Log ç³»çµ±
# =====================================================
class Logger:
    def __init__(self, log_buffer):
        self.terminal = sys.stdout
        self.log = log_buffer
    def write(self, message):
        self.terminal.write(message)
        self.log.write(message)
    def flush(self):
        self.terminal.flush()

sys.stdout = Logger(log_buffer)

print("=" * 60)
print(f"ğŸ¬ IMDb Rating é›™æ¨¡å‹è¨“ç·´é–‹å§‹ ({datetime.now().strftime('%Y-%m-%d %H:%M:%S')})")
print("=" * 60)

# =====================================================
# ğŸ“„ è³‡æ–™è®€å–
# =====================================================
feature_path = Path("data/ML_rating/ML_data_PART2/ML_add_extag/merged_full_dataset_full_extag_add_tree_feature.csv")
target_path  = Path("data/ML_rating/ML_data_PART2/ML_add_extag/merged_full_dataset_extag_add_tree_target.csv")

X = pd.read_csv(feature_path)
y = pd.read_csv(target_path)

# è‡ªå‹•ç§»é™¤ gov_id
if "gov_id" in X.columns:
    X = X.drop(columns=["gov_id"])
if "gov_id" in y.columns:
    y = y.drop(columns=["gov_id"])

# åµæ¸¬æ–‡å­—æ¬„ä½ â†’ OneHot ç·¨ç¢¼
cat_cols = X.select_dtypes(include=["object"]).columns.tolist()
if len(cat_cols) > 0:
    print(f"ğŸ”  åµæ¸¬åˆ°æ–‡å­—æ¬„ä½ {len(cat_cols)} å€‹ï¼ŒåŸ·è¡Œ OneHot ç·¨ç¢¼: {cat_cols}")
    X = pd.get_dummies(X, columns=cat_cols, drop_first=True)

# å¡«è£œç¼ºå¤±å€¼
if X.isna().sum().sum() > 0:
    print(f"âš ï¸ ç™¼ç¾ {X.isna().sum().sum()} å€‹ NaNï¼Œè‡ªå‹•ä»¥ 0 è£œå€¼")
    X = X.fillna(0)
if y.isna().sum().sum() > 0:
    print(f"âš ï¸ ç›®æ¨™æ¬„ä½æœ‰ NaNï¼Œè‡ªå‹•ä»¥ 0 è£œå€¼")
    y = y.fillna(0)

print(f"ğŸ“Š æ¸…ç†å¾Œè³‡æ–™ç­†æ•¸: X={len(X)}, y={len(y)}")
print(f"âœ… ç‰¹å¾µæ¬„ä½æ•¸: {X.shape[1]}")

# =====================================================
# ğŸ”€ åˆ†å‰²è¨“ç·´/æ¸¬è©¦é›†
# =====================================================
y = y.iloc[:, 0]  # å–ç¬¬ä¸€æ¬„ imdb_rating
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
print(f"\nğŸ“š è¨“ç·´é›†: {len(X_train)} ç­†, æ¸¬è©¦é›†: {len(X_test)} ç­†")

# =====================================================
# ğŸŸ¢ æ¨¡å‹ 1: LightGBM
# =====================================================
print("\n" + "=" * 50)
print("ğŸŸ¢ æ¨¡å‹ 1: LightGBM")
print("=" * 50)

lgb_model = lgb.LGBMRegressor(
    n_estimators=400,
    learning_rate=0.05,
    max_depth=6,
    random_state=42,
    verbose=-1
)
lgb_model.fit(X_train, y_train)
y_pred_lgb = lgb_model.predict(X_test)

mae_lgb = mean_absolute_error(y_test, y_pred_lgb)
rmse_lgb = np.sqrt(mean_squared_error(y_test, y_pred_lgb))
r2_lgb = r2_score(y_test, y_pred_lgb)

print(f"MAE:  {mae_lgb:.4f}")
print(f"RMSE: {rmse_lgb:.4f}")
print(f"RÂ²:   {r2_lgb:.4f}")

# =====================================================
# ğŸŒ² æ¨¡å‹ 2: Random Forest
# =====================================================
print("\n" + "=" * 50)
print("ğŸŒ² æ¨¡å‹ 2: Random Forest")
print("=" * 50)

rf = RandomForestRegressor(
    n_estimators=400,
    max_depth=20,
    min_samples_leaf=2,
    random_state=80,
    n_jobs=-1
)
rf.fit(X_train, y_train)
y_pred_rf = rf.predict(X_test)

mae_rf = mean_absolute_error(y_test, y_pred_rf)
rmse_rf = np.sqrt(mean_squared_error(y_test, y_pred_rf))
r2_rf = r2_score(y_test, y_pred_rf)
print(f"MAE:  {mae_rf:.4f}")
print(f"RMSE: {rmse_rf:.4f}")
print(f"RÂ²:   {r2_rf:.4f}")

# =====================================================
# ğŸ“Š ç‰¹å¾µé‡è¦æ€§è¼¸å‡º
# =====================================================
feature_importance = pd.DataFrame({
    "feature": X.columns,
    "LightGBM_Importance": lgb_model.feature_importances_,
    "RandomForest_Importance": rf.feature_importances_
}).sort_values("LightGBM_Importance", ascending=False)

feature_importance.to_csv(output_dir / "feature_importance_2models.csv", index=False, encoding="utf-8-sig")
print(f"âœ… ç‰¹å¾µé‡è¦æ€§å·²å­˜æª”: {output_dir / 'feature_importance_2models.csv'}")

# =====================================================
# ğŸ“ˆ å¯è¦–åŒ–ï¼šå…©æ¨¡å‹é æ¸¬æ¯”è¼ƒ
# =====================================================
plt.rcParams["font.sans-serif"] = ["Microsoft JhengHei"]
plt.rcParams["axes.unicode_minus"] = False

fig, axes = plt.subplots(1, 2, figsize=(12, 5))  # âœ… æ”¹æˆ 1x2 æ’ç‰ˆ
models = [
    ("LightGBM", y_pred_lgb, r2_lgb),
    ("Random Forest", y_pred_rf, r2_rf)
]

for ax, (name, pred, r2) in zip(axes, models):
    ax.scatter(y_test, pred, alpha=0.6, s=20)
    ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], "r--")
    ax.set_title(f"{name} (RÂ²={r2:.3f})")
    ax.set_xlabel("å¯¦éš› IMDb è©•åˆ†")
    ax.set_ylabel("é æ¸¬ IMDb è©•åˆ†")
    ax.grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig(output_dir / "rating_prediction_2models.png", dpi=150, bbox_inches="tight")
plt.close()
print(f"âœ… æ¨¡å‹é æ¸¬æ¯”è¼ƒåœ–å·²è¼¸å‡º: {output_dir / 'rating_prediction_2models.png'}")

# =====================================================
# ğŸ’¾ æ¨¡å‹ä¿å­˜
# =====================================================
joblib.dump(lgb_model, output_dir / "model_lightgbm.pkl")
joblib.dump(rf, output_dir / "model_randomforest.pkl")
print(f"âœ… æ¨¡å‹å·²ä¿å­˜è‡³: {output_dir}")

# =====================================================
# ğŸ§¾ æ¸¬è©¦é›†é æ¸¬çµæœ
# =====================================================
results = pd.DataFrame({
    "actual": y_test,
    "pred_lightgbm": y_pred_lgb,
    "pred_randomforest": y_pred_rf
})
results.to_csv(output_dir / "test_predictions_2models.csv", index=False, encoding="utf-8-sig")
print(f"âœ… æ¸¬è©¦é›†é æ¸¬çµæœå·²å­˜æª”: {output_dir / 'test_predictions_2models.csv'}")

# =====================================================
# ğŸ“˜ Log å„²å­˜
# =====================================================
sys.stdout = sys.stdout.terminal
with open(log_file, "w", encoding="utf-8") as f:
    f.write(log_buffer.getvalue())

print("\n" + "=" * 60)
print(f"ğŸ‰ æ¨¡å‹è¨“ç·´å®Œæˆ! Log å·²ä¿å­˜æ–¼: {log_file}")
print("=" * 60)
