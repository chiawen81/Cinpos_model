# uv run src\ML_rating\train_Model_Rating\train_rating_models_add_tree.py
# =====================================================
# ğŸ¬ IMDb Rating å››æ¨¡å‹è¨“ç·´ (Linear / LightGBM / DecisionTree / RandomForest)
# ğŸ§  è‡ªå‹• OneHot + NaN è£œå€¼ + ç‰¹å¾µé‡è¦æ€§ + åœ–è¡¨åŒ–
# =====================================================
import pandas as pd
import numpy as np
import sys
from pathlib import Path
from io import StringIO
from datetime import datetime
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor, plot_tree
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import lightgbm as lgb
import joblib
import matplotlib.pyplot as plt

# =====================================================
# ğŸ“ è¼¸å‡ºè³‡æ–™å¤¾è¨­å®š
# =====================================================
output_dir = Path("data/ML_rating/4type_rating_models_PART3")
output_dir.mkdir(parents=True, exist_ok=True)
timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
log_file = output_dir / f"training_log_{timestamp}.txt"
log_buffer = StringIO()

class Logger:
    def __init__(self, log_buffer):
        self.terminal = sys.stdout
        self.log = log_buffer
    def write(self, message):
        self.terminal.write(message)
        self.log.write(message)
    def flush(self):
        self.terminal.flush()

sys.stdout = Logger(log_buffer)

print("=" * 60)
print(f"ğŸ¬ IMDb Rating å››æ¨¡å‹è¨“ç·´é–‹å§‹ ({datetime.now().strftime('%Y-%m-%d %H:%M:%S')})")
print("=" * 60)

# =====================================================
# ğŸ“„ è³‡æ–™è®€å–
# =====================================================
feature_path = Path("data/ML_rating/ML_data_PART2/ML_add_extag/merged_full_dataset_full_extag_add_tree_feature.csv")
target_path  = Path("data/ML_rating/ML_data_PART2/ML_add_extag/merged_full_dataset_extag_add_tree_target.csv")
df_X = pd.read_csv(feature_path)
df_y = pd.read_csv(target_path)

# =====================================================
# ğŸ§¹ å‰è™•ç†ï¼šç§»é™¤ ID æ¬„ä½
# =====================================================
for col in ["gov_id", "movie_id", "id"]:
    if col in df_X.columns:
        df_X = df_X.drop(columns=[col], errors="ignore")
    if col in df_y.columns:
        df_y = df_y.drop(columns=[col], errors="ignore")

# =====================================================
# ğŸ§  è‡ªå‹•ç·¨ç¢¼æ–‡å­—é¡ç‰¹å¾µ
# =====================================================
categorical_cols = df_X.select_dtypes(include=["object"]).columns.tolist()
if categorical_cols:
    print(f"ğŸ”  åµæ¸¬åˆ°æ–‡å­—æ¬„ä½ {len(categorical_cols)} å€‹ï¼ŒåŸ·è¡Œ OneHot ç·¨ç¢¼: {categorical_cols}")
    df_X = pd.get_dummies(df_X, columns=categorical_cols, drop_first=True)
else:
    print("âœ… ç„¡æ–‡å­—æ¬„ä½å¯ç·¨ç¢¼")

# =====================================================
# ğŸ” ç¼ºå¤±å€¼è™•ç†
# =====================================================
if df_X.isna().sum().sum() > 0:
    print(f"âš ï¸ ç™¼ç¾ {df_X.isna().sum().sum()} å€‹ NaNï¼Œå·²è‡ªå‹•ä»¥ 0 è£œå€¼")
    df_X = df_X.fillna(0)
if df_y.isna().sum().sum() > 0:
    print(f"âš ï¸ ç›®æ¨™æ¬„æœ‰ {df_y.isna().sum().sum()} å€‹ NaNï¼Œå·²è‡ªå‹•ä»¥ 0 è£œå€¼")
    df_y = df_y.fillna(0)

# =====================================================
# ğŸ¯ ç›®æ¨™è®Šæ•¸
# =====================================================
if "imdb_rating" in df_y.columns:
    y = df_y["imdb_rating"]
else:
    y = df_y.iloc[:, 0]
X = df_X.select_dtypes(include=["number"]).fillna(0)

print(f"ğŸ“Š æ¸…ç†å¾Œè³‡æ–™ç­†æ•¸: X={len(X)}, y={len(y)}")
print(f"âœ… ç‰¹å¾µæ¬„ä½æ•¸: {X.shape[1]}")

# =====================================================
# ğŸ”€ è¨“ç·´ / æ¸¬è©¦é›†åˆ‡åˆ†
# =====================================================
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)
print(f"\nğŸ“š è¨“ç·´é›†: {len(X_train)} ç­†, æ¸¬è©¦é›†: {len(X_test)} ç­†")

# =====================================================
# ğŸ”µ æ¨¡å‹ 1: ç·šæ€§å›æ­¸
# =====================================================
print("\n" + "=" * 50)
print("ğŸ”µ æ¨¡å‹ 1: Linear Regression")
print("=" * 50)

lr = LinearRegression()
lr.fit(X_train, y_train)
y_pred_lr = lr.predict(X_test)

mae_lr = mean_absolute_error(y_test, y_pred_lr)
rmse_lr = np.sqrt(mean_squared_error(y_test, y_pred_lr))
r2_lr = r2_score(y_test, y_pred_lr)
print(f"MAE:  {mae_lr:.4f}")
print(f"RMSE: {rmse_lr:.4f}")
print(f"RÂ²:   {r2_lr:.4f}")

# =====================================================
# ğŸŸ¢ æ¨¡å‹ 2: LightGBM
# =====================================================
print("\n" + "=" * 50)
print("ğŸŸ¢ æ¨¡å‹ 2: LightGBM")
print("=" * 50)

lgb_model = lgb.LGBMRegressor(
    n_estimators=400,
    learning_rate=0.05,
    max_depth=10,
    random_state=40,
    verbose=-1
)
lgb_model.fit(X_train, y_train)
y_pred_lgb = lgb_model.predict(X_test)

mae_lgb = mean_absolute_error(y_test, y_pred_lgb)
rmse_lgb = np.sqrt(mean_squared_error(y_test, y_pred_lgb))
r2_lgb = r2_score(y_test, y_pred_lgb)
print(f"MAE:  {mae_lgb:.4f}")
print(f"RMSE: {rmse_lgb:.4f}")
print(f"RÂ²:   {r2_lgb:.4f}")

# =====================================================
# ğŸŒ³ æ¨¡å‹ 3: Decision Tree
# =====================================================
# 

print("\n" + "=" * 50)
print("ğŸŒ³ æ¨¡å‹ 3: Decision Tree")
print("=" * 50)

tree = DecisionTreeRegressor(max_depth=8, random_state=80)
tree.fit(X_train, y_train)
y_pred_tree = tree.predict(X_test)

mae_tree = mean_absolute_error(y_test, y_pred_tree)
rmse_tree = np.sqrt(mean_squared_error(y_test, y_pred_tree))
r2_tree = r2_score(y_test, y_pred_tree)
print(f"MAE:  {mae_tree:.4f}")
print(f"RMSE: {rmse_tree:.4f}")
print(f"RÂ²:   {r2_tree:.4f}")
# =====================================================
# ğŸŒ³ æ±ºç­–æ¨¹åœ–å½¢å¯è¦–åŒ–ï¼ˆå« MSEã€RMSEã€samplesã€valueï¼‰
# =====================================================
import matplotlib.pyplot as plt
from sklearn.tree import plot_tree
import numpy as np

plt.figure(figsize=(30, 26))
plt.rcParams["font.sans-serif"] = ["Microsoft JhengHei"]
plt.rcParams["axes.unicode_minus"] = False

# å…ˆå–å¾—æ¨¹çš„å…§éƒ¨çµæ§‹
tree_ = tree.tree_

# å»ºç«‹è‡ªè¨‚ç¯€é»æ¨™ç±¤ï¼ˆåŒ…å« RMSEï¼‰
node_labels = []
for i in range(tree_.node_count):
    mse = tree_.impurity[i]
    rmse = np.sqrt(mse) if mse > 0 else 0.0  # é˜²æ­¢æµ®é»è² å€¼
    samples = tree_.n_node_samples[i]
    value = tree_.value[i][0][0]
    node_labels.append(f"MSE={mse:.3f}\nRMSE={rmse:.3f}\nSamples={samples}\nValue={value:.3f}")

# ä½¿ç”¨ plot_tree ä¸¦æ‰‹å‹•å¥—ä¸Šç¯€é»æ¨™ç±¤
plot_tree(
    tree,
    feature_names=X.columns,
    filled=True,
    rounded=True,
    fontsize=16,
    impurity=False,
    node_ids=True,
)

# æ›¿æ¯å€‹ç¯€é»åŠ ä¸Šè‡ªè¨‚æ–‡å­—ï¼ˆå« RMSE ç­‰è³‡è¨Šï¼‰
ax = plt.gca()
for t in ax.texts:
    node_text = t.get_text().split('\n')[0]
    node_id = None
    if "node" in node_text:
        node_id = int(node_text.replace("node #", "").strip())
    elif node_text.isdigit():
        node_id = int(node_text)
    if node_id is not None and node_id < len(node_labels):
        t.set_text(node_labels[node_id])

plt.title("Decision Tree with MSE / RMSE / Samples / Value", fontsize=14)
plt.tight_layout()
plt.savefig(output_dir / "decision_tree_with_metrics.png", dpi=300)
plt.close()
print(f"âœ… æ±ºç­–æ¨¹åœ–å½¢ï¼ˆå« MSEã€RMSEã€samplesã€valueï¼‰å·²è¼¸å‡ºï¼š{output_dir / 'decision_tree_with_metrics.png'}")

# =====================================================
# ğŸŒ² æ¨¡å‹ 4: Random Forest
# =====================================================
print("\n" + "=" * 50)
print("ğŸŒ² æ¨¡å‹ 4: Random Forest")
print("=" * 50)

rf = RandomForestRegressor(
    n_estimators=400,
    max_depth=200,
    random_state=35
)
rf.fit(X_train, y_train)
y_pred_rf = rf.predict(X_test)

mae_rf = mean_absolute_error(y_test, y_pred_rf)
rmse_rf = np.sqrt(mean_squared_error(y_test, y_pred_rf))
r2_rf = r2_score(y_test, y_pred_rf)
print(f"MAE:  {mae_rf:.4f}")
print(f"RMSE: {rmse_rf:.4f}")
print(f"RÂ²:   {r2_rf:.4f}")

# =====================================================
# ğŸ“Š ç‰¹å¾µé‡è¦æ€§è¼¸å‡º
# =====================================================
feature_importance = pd.DataFrame({
    "feature": X.columns,
    "Linear_Coeff": np.abs(lr.coef_),
    "LightGBM_Importance": lgb_model.feature_importances_,
    "Tree_Importance": tree.feature_importances_,
    "RandomForest_Importance": rf.feature_importances_
}).sort_values("LightGBM_Importance", ascending=False)

feature_importance.to_csv(output_dir / "feature_importance_4model.csv", index=False, encoding="utf-8-sig")
print(f"âœ… ç‰¹å¾µé‡è¦æ€§å·²å­˜æª”: {output_dir / 'feature_importance_4model.csv'}")

# =====================================================
# ğŸ“ˆ å¯è¦–åŒ–ï¼šå››æ¨¡å‹é æ¸¬æ¯”è¼ƒ
# =====================================================
plt.rcParams["font.sans-serif"] = ["Microsoft JhengHei"]
plt.rcParams["axes.unicode_minus"] = False

fig, axes = plt.subplots(2, 2, figsize=(14, 10))
models = [
    ("Linear Regression", y_pred_lr, r2_lr),
    ("LightGBM", y_pred_lgb, r2_lgb),
    ("Decision Tree", y_pred_tree, r2_tree),
    ("Random Forest", y_pred_rf, r2_rf)
]

for ax, (name, pred, r2) in zip(axes.flatten(), models):
    ax.scatter(y_test, pred, alpha=0.6, s=20)
    ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], "r--")
    ax.set_title(f"{name} (RÂ²={r2:.3f})")
    ax.set_xlabel("å¯¦éš› IMDb è©•åˆ†")
    ax.set_ylabel("é æ¸¬ IMDb è©•åˆ†")
    ax.grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig(output_dir / "rating_prediction_4models.png", dpi=150, bbox_inches="tight")
plt.close()
print(f"âœ… æ¨¡å‹é æ¸¬æ¯”è¼ƒåœ–å·²è¼¸å‡º: {output_dir / 'rating_prediction_4models.png'}")

# =====================================================
# ğŸ’¾ æ¨¡å‹ä¿å­˜
# =====================================================
joblib.dump(lr, output_dir / "model_linear.pkl")
joblib.dump(lgb_model, output_dir / "model_lightgbm.pkl")
joblib.dump(tree, output_dir / "model_decision_tree.pkl")
joblib.dump(rf, output_dir / "model_random_forest.pkl")
print(f"âœ… æ‰€æœ‰æ¨¡å‹å·²ä¿å­˜è‡³: {output_dir}")

# =====================================================
# ğŸ§¾ æ¸¬è©¦é›†é æ¸¬çµæœ
# =====================================================
results = pd.DataFrame({
    "actual": y_test,
    "pred_lr": y_pred_lr,
    "pred_lgb": y_pred_lgb,
    "pred_tree": y_pred_tree,
    "pred_rf": y_pred_rf
})
results.to_csv(output_dir / "test_predictions_4models.csv", index=False, encoding="utf-8-sig")
print(f"âœ… æ¸¬è©¦é›†é æ¸¬çµæœå·²å­˜æª”: {output_dir / 'test_predictions_4models.csv'}")

# =====================================================
# ğŸ“˜ Log å„²å­˜
# =====================================================
sys.stdout = sys.stdout.terminal
with open(log_file, "w", encoding="utf-8") as f:
    f.write(log_buffer.getvalue())

print("\n" + "=" * 60)
print(f"ğŸ‰ æ¨¡å‹è¨“ç·´å®Œæˆ! Log å·²ä¿å­˜æ–¼: {log_file}")
print("=" * 60)

