"""
æ”¿åºœå…¬é–‹è³‡æ–™ï¼šã€Šå…¨åœ‹é›»å½±ç¥¨æˆ¿çµ±è¨ˆè³‡è¨Šã€‹çˆ¬èŸ²
------------------------------------------------
ç›®æ¨™ï¼š
    ä»¥ã€Šå…¨åœ‹é›»å½±ç¥¨æˆ¿çµ±è¨ˆè³‡è¨Šã€‹æ¯å‘¨é›»å½±ç¥¨æˆ¿çš„åå–®ç‚ºåŸºæº–
    ï¼ˆå­˜åœ¨ data/processed/boxoffice_weekly/boxoffice_<é€±æœŸ>_<æ—¥æœŸç¯„åœ>.csvï¼‰ï¼Œ
    é€ä¸€æŸ¥è©¢è©²é›»å½±çš„ã€Œç´¯è¨ˆç¥¨æˆ¿çµ±è¨ˆè³‡æ–™ã€ã€‚

è³‡æ–™ä¾†æºï¼š
    1. æ¯å‘¨é›»å½±ç¥¨æˆ¿ï¼ˆå·²æ¸…ç†å®Œçš„CSVï¼‰
       data/processed/boxoffice_weekly/boxoffice_<é€±æœŸ>_<æ—¥æœŸç¯„åœ>.csv
       æ¬„ä½é‡é»ï¼šmovieId, name

    2. æ”¿åºœé›»å½±ç¥¨æˆ¿çµ±è¨ˆè©³ç´°é 
       https://boxofficetw.tfai.org.tw/film/gfd/<é›»å½±id>
"""

# ========= å¥—ä»¶åŒ¯å…¥ =========
import os
import time
import requests
import pandas as pd
from pathlib import Path

# å…±ç”¨æ¨¡çµ„
from common.path_utils import (
    BOXOFFICE_PERMOVIE_RAW,
    BOXOFFICE_PROCESSED,
)
from common.network_utils import get_default_headers
from common.file_utils import ensure_dir, save_json, clean_filename
from common.date_utils import get_week_label, get_year_label
from common.mapping_utils import load_manual_mapping, find_manual_mapping

# ========= å…¨åŸŸè¨­å®š =========
SEARCH_URL = "https://boxofficetw.tfai.org.tw/film/sf?keyword="
DETAIL_URL = "https://boxofficetw.tfai.org.tw/film/gfd/"
HEADERS = get_default_headers()
TIMEOUT = 10
SLEEP_INTERVAL = 1.2  # é¿å…é€£çºŒè«‹æ±‚éå¿«è¢«é™åˆ¶
WEEK_LABEL = get_week_label()
YEAR_LABEL = get_year_label()


# ========= è¼”åŠ©å‡½å¼ =========
# æŠ“ç¥¨æˆ¿è³‡æ–™
def fetch_boxoffice_data(film_id: str) -> dict | None:
    """æ ¹æ“šé›»å½± ID æŠ“å–ç¥¨æˆ¿çµ±è¨ˆè³‡æ–™"""
    try:
        res = requests.get(DETAIL_URL + film_id, headers=HEADERS, timeout=TIMEOUT)
        res.encoding = "utf-8"
        data = res.json()
        return data
    except Exception as e:
        print(f"âŒ ç¥¨æˆ¿è³‡æ–™æŠ“å–å¤±æ•—ï¼šID={film_id} ({e})")
        return None


# ========= ä¸»çˆ¬èŸ²é‚è¼¯ =========
def fetch_boxoffice_permovie_from_weekly() -> None:
    """
    ä»¥æ¯é€±ç¥¨æˆ¿åå–®ç‚ºåŸºæº–ï¼Œé€ä¸€æŠ“å–å–®éƒ¨é›»å½±çš„ç¥¨æˆ¿çµ±è¨ˆè³‡æ–™ã€‚
    """

    # --- å‰ç½® ---
    ready_crawler_num = 0  # é è¨ˆè¦æ’ˆå–çš„é›»å½±æ•¸
    success_crawler_num = 0  # æˆåŠŸæ’ˆå–çš„é›»å½±æ•¸

    # ------------------------------------------------
    # å–å¾—é›»å½±åå–®èˆ‡id
    # ------------------------------------------------
    boxoffice_weekly_dir = os.path.join(BOXOFFICE_PROCESSED, YEAR_LABEL)

    # ğŸ” éè¿´æœå°‹è©²å¹´ä»½åº•ä¸‹ç¬¦åˆé€±æœŸåç¨±çš„ CSV æª”æ¡ˆ
    matches = list(Path(boxoffice_weekly_dir).rglob(f"boxoffice_{WEEK_LABEL}_*.csv"))

    if not matches:
        print(f"âš ï¸ æ‰¾ä¸åˆ°æœ€è¿‘ä¸€é€±çš„é€±ç¥¨æˆ¿è³‡æ–™ï¼š{boxoffice_weekly_dir}")
        return

    boxoffice_this_week_filePath = str(matches[0])

    print("-------------------------------")
    print(f"æœ¬å‘¨ç¥¨æˆ¿æª”æ¡ˆï¼š{boxoffice_this_week_filePath}")

    # è®€å–æª”æ¡ˆ
    df_weekly = pd.read_csv(boxoffice_this_week_filePath)

    if "movieId" not in df_weekly.columns:
        print("âŒ æª”æ¡ˆç¼ºå°‘å¿…è¦æ¬„ä½ 'movieId'")
        return

    ready_crawler_num = len(df_weekly)
    print(f"ğŸ“Š å…± {ready_crawler_num} éƒ¨é›»å½±å¾…æŸ¥è©¢ç¥¨æˆ¿è©³ç´°è³‡æ–™\n")

    # ------------------------------------------------
    # å–å¾—è¼¸å‡ºè³‡æ–™å¤¾è·¯å¾‘
    # ------------------------------------------------
    output_dir = os.path.join(BOXOFFICE_PERMOVIE_RAW, YEAR_LABEL, WEEK_LABEL)
    ensure_dir(output_dir)

    # ------------------------------------------------
    # é–‹å§‹é€éƒ¨é›»å½±æŠ“å–
    # ------------------------------------------------
    for _, row in df_weekly.iterrows():
        movie_id = str(row["movieId"]).strip()
        movie_name = row.get("name", "")
        clean_movie_name = clean_filename(movie_name)

        if not movie_id or movie_id == "nan":
            print(f"âš ï¸ ç„¡æœ‰æ•ˆ movieIdï¼Œç•¥éï¼š{movie_name}")
            continue

        # æŠ“å–å–®éƒ¨é›»å½±è³‡æ–™
        crawler_data = fetch_boxoffice_data(movie_id)

        # å„²å­˜æˆ JSON
        file_name = f"{movie_id}_{clean_movie_name}_{WEEK_LABEL}.json"
        save_json(crawler_data, output_dir, file_name)
        print(f"âœ… å·²å„²å­˜ï¼š{file_name}")
        success_crawler_num += 1

        time.sleep(SLEEP_INTERVAL)

    # ------------------------------------------------
    # çµ±è¨ˆè¼¸å‡º
    # ------------------------------------------------
    print("\n==============================")
    print("ğŸ‰ å–®ä¸€é›»å½±ç¥¨æˆ¿ç´¯è¨ˆè³‡æ–™ å·²æŠ“å–å®Œæˆ")
    print(f"ã€€é€±æœŸï¼š{WEEK_LABEL}")
    print(f"ã€€é è¨ˆæ’ˆå–é›»å½±æ•¸é‡ï¼š{ready_crawler_num}")
    print(f"ã€€æˆåŠŸæ’ˆå–é›»å½±æ•¸é‡ï¼š{success_crawler_num}")
    print(f"ã€€æœªæˆåŠŸæ’ˆå–ï¼š{ready_crawler_num - success_crawler_num}")
    print(f"ğŸ“ è¼¸å‡ºè³‡æ–™å¤¾ï¼š{output_dir}")
    print("==============================\n")


# ========= ä¸»ç¨‹å¼åŸ·è¡Œå€ =========
if __name__ == "__main__":
    print(f"ğŸ“… æœ¬æ¬¡åŸ·è¡Œé€±æœŸ(æœ€è¿‘ä¸€å‘¨)ï¼š{WEEK_LABEL}")
    fetch_boxoffice_permovie_from_weekly()
