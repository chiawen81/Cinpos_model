"""
IMDb / OMDb è©•åˆ†è³‡æ–™çˆ¬å–
----------------------------------
ç›®æ¨™ï¼š
    æ’ˆå–ç•¶é€±é¦–è¼ªé›»å½±çš„ IMDb / OMDb è©•åˆ†è³‡æ–™

æ­¥é©Ÿï¼š
    step1. è®€å–ç•¶é€±ã€Šé¦–è¼ªé›»å½±åå–®ã€‹
    step2. æ‰¿ä¸Šï¼Œæ ¹æ“š atmovies_id æ‰¾å‡ºå°æ‡‰ imdb_id
    step3. å‘¼å« OMDb APIï¼Œå–å¾— imdbRatingã€imdbVotesã€Metascoreã€Ratings ç­‰è©•åˆ†è³‡æ–™

çˆ¬èŸ²ç›®æ¨™APIï¼š
   https://www.omdbapi.com/?apikey=<OMDB_API_KEY>6&i=<IMDB_ID>&plot=full

è¼¸å…¥ä¾†æºï¼š
    - å–å¾—ç•¶å‘¨é¦–è¼ªé›»å½±ï¼šdata/processed/firstRunFilm_list/<ç•¶å‘¨>/firstRun_<ç•¶å‘¨>.csv
    - å–å¾—æ¯éƒ¨é›»å½±å°æ‡‰çš„imdb IDï¼šdata/processed/movieInfo_omdb/movieInfo_omdb_<ä¸Šæ¬¡åŸ·è¡Œæ—¥æœŸ>.csv

è¼¸å‡ºï¼š
    - æˆåŠŸè³‡æ–™ï¼šdata/raw/rating_weekly/<ç•¶é€±>/rating_<ç•¶é€±>.json
    - éŒ¯èª¤ç´€éŒ„ï¼šdata/raw/rating_weekly/error/error_<timestamp>.json
"""

# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€” å¥—ä»¶åŒ¯å…¥ â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
import os
import time
import requests
import pandas as pd
from datetime import datetime
from dotenv import load_dotenv

# å…±ç”¨æ¨¡çµ„
from common.path_utils import RATING_WEEKLY_RAW, FIRSTRUN_PROCESSED, OMDB_PROCESSED
from common.file_utils import ensure_dir, save_json
from common.date_utils import get_current_week_label, create_timestamped


# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€” å…¨åŸŸè¨­å®š â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
load_dotenv()
OMDB_API_KEY = os.getenv("OMDB_API_KEY")
WEEK_LABEL = get_current_week_label()
OUTPUT_DIR = os.path.join(RATING_WEEKLY_RAW, WEEK_LABEL)
ERROR_DIR = os.path.join(RATING_WEEKLY_RAW, "error")
ensure_dir(OUTPUT_DIR)
ensure_dir(ERROR_DIR)


# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€” å·¥å…·å‡½å¼ â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
def fetch_omdb_rating(imdb_id: str) -> dict:
    """æ‰“ OMDb APIï¼Œå–å¾—é›»å½±è©•åˆ†è³‡æ–™"""
    url = f"https://www.omdbapi.com/?apikey={OMDB_API_KEY}&i={imdb_id}&plot=full"

    try:
        response = requests.get(url, timeout=10)
        data = response.json()
        if data.get("Response") == "False":
            return {"error": data.get("Error", "Movie not found")}
        return data
    except Exception as e:
        return {"error": str(e)}


def create_error_record(errors: list):
    """è¼¸å‡ºéŒ¯èª¤ç´€éŒ„"""
    if errors:
        fileName = f"error_{create_timestamped()}.json"

        for row in errors:
            print(f"  - {row['atmovies_title_zh']} (atmovies_idï¼š{row['atmovies_id']})")
        save_json(errors, ERROR_DIR, fileName, "<éŒ¯èª¤ç´€éŒ„>")


# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€” ä¸»ç¨‹å¼ â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
def fetch_weekly_ratings():
    print(f"ğŸ¬ é–‹å§‹æ’ˆå– IMDb / OMDb è©•åˆ†è³‡æ–™ï¼ˆé€±æ¬¡ï¼š{WEEK_LABEL}ï¼‰")
    errors_record = []  # ç•°å¸¸è³‡æ–™

    # --------------------------------------------
    # Step 1ï¼šè®€å–ç•¶é€±é¦–è¼ªé›»å½±æ¸…å–®
    # --------------------------------------------
    first_run_path = os.path.join(FIRSTRUN_PROCESSED, WEEK_LABEL, f"firstRun_{WEEK_LABEL}.csv")
    ### è™•ç†ä¾‹å¤–ç‹€æ³1ï¼šç„¡æœ¬å‘¨é¦–è¼ªé›»å½±æ¸…å–®
    if not os.path.exists(first_run_path):
        print(f"âŒ æ‰¾ä¸åˆ°é¦–è¼ªé›»å½±æ¸…å–®ï¼š{first_run_path}")
        return

    first_run_df = pd.read_csv(first_run_path, encoding="utf-8")
    print(f"ğŸ“‚ é¦–è¼ªé›»å½±ç­†æ•¸ï¼š{len(first_run_df)}")

    # --------------------------------------------
    # Step 2ï¼šè®€å–ç¾æœ‰ OMDb è³‡æ–™
    # --------------------------------------------
    omdb_files = [f for f in os.listdir(OMDB_PROCESSED) if f.endswith(".csv")]

    ### è™•ç†ä¾‹å¤–ç‹€æ³2ï¼šç„¡movieInfo_omdb_*.csv
    if not omdb_files:
        print(f"âŒ æ‰¾ä¸åˆ° OMDb å°ç…§è³‡æ–™ï¼š{OMDB_PROCESSED}")
        return

    # å–å¾—æœ€æ–°çš„ movieInfo_omdb_*.csv
    omdb_latest = max(omdb_files, key=lambda x: os.path.getmtime(os.path.join(OMDB_PROCESSED, x)))

    # è®€å–æœ€æ–°çš„ CSV æª”æˆç‚º pandas.DataFrame
    omdb_path = os.path.join(OMDB_PROCESSED, omdb_latest)
    omdb_df = pd.read_csv(omdb_path, encoding="utf-8")
    print("====================================")
    print(f"ğŸ” ä½¿ç”¨ OMDb å°ç…§è³‡æ–™ï¼š{omdb_latest}")
    print("====================================\n")

    # --------------------------------------------
    # Step 3ï¼šåˆä½µå…©å¼µè³‡æ–™è¡¨(æœ¬å‘¨é¦–è¼ªåå–®ã€omdb)
    # --------------------------------------------
    merged = first_run_df.merge(
        omdb_df[["gov_id", "atmovies_id", "imdb_id", "omdb_title_en"]],
        on="atmovies_id",
        how="left",
    )
    """NOTE:
        1. éˆæ¥æ¬„ä½ï¼šç”¨ atmovies_id é€™å€‹æ¬„ä½åšã€Œå·¦é€£æ¥ï¼ˆleft joinï¼‰ã€ï¼š
        2. å·¦å³è¡¨ï¼š
            - å·¦è¡¨æ˜¯æœ¬é€±çš„é¦–è¼ªé›»å½±æ¸…å–®(first_run_df)
            - å³è¡¨æ˜¯ OMDb çš„å®Œæ•´è³‡æ–™(omdb_df)
        3. æŒ‘å‡º omdb_df ä¸­çš„ç›¸é—œæ¬„ä½åˆä½µè‡³ first_run_dfï¼š
            => omdb_df[["gov_id", "imdb_id",......]],
            => éˆæ¥æ¬„ä½é ˆåŒ…å«åœ¨ omdb_df ä¸­ï¼ˆatmovies_idï¼‰
    """

    # --------------------------------------------
    # Step 4ï¼šé‡æ–°çˆ¬ OMDB è³‡æ–™ (å–å¾—æœ€æ–°è©•åˆ†è³‡æ–™)
    # --------------------------------------------
    omdb_rating_data = []

    for _, row in merged.iterrows():
        imdb_id = row["imdb_id"] or ""
        atmovies_title_zh = row.get("atmovies_title_zh") or ""

        ##### å¯«å…¥éŒ¯èª¤è¨Šæ¯ï¼šç„¡gov_id/imdb/omdbè³‡æ–™
        if not row["gov_id"] or pd.isna(row["gov_id"]):
            errors_record.append(
                {
                    "atmovies_id": row["atmovies_id"],
                    "atmovies_title_zh": row["atmovies_title_zh"],
                    "gov_id": "",
                    "imdb_id": "",
                    "errorType": "without gov_id/imdb/omdb data",
                    "errorMsg": "ç„¡è³‡æ–™(é ˆçœ‹fix_omdb_mapping.jsonç¢ºèª)",
                }
            )
            continue

        # çˆ¬ OMDb è³‡æ–™
        omdb_crawler_data = fetch_omdb_rating(imdb_id)

        ##### å¯«å…¥éŒ¯èª¤è¨Šæ¯ï¼šAPIéŒ¯èª¤
        if "Error" in omdb_crawler_data:
            print(f"âŒ {atmovies_title_zh}- {omdb_crawler_data['error']}")
            errors_record.append(
                {
                    "atmovies_id": row["atmovies_id"],
                    "atmovies_title_zh": atmovies_title_zh,
                    "gov_id": row["gov_id"],
                    "imdb_id": imdb_id,
                    "errorType": "API response error",
                    "errorMsg": omdb_crawler_data["error"],
                }
            )
            continue

        # --------------------------------------------
        # Step 5ï¼šæ•´ç†è³‡æ–™
        # --------------------------------------------
        # æœ¬æ¬¡åŸ·è¡Œè³‡è¨Š
        crawl_note = {
            "gov_id": row["gov_id"],
            "atmovies_id": row["atmovies_id"],
            "atmovies_title_zh": atmovies_title_zh,
            "imdb_id": imdb_id,
            "source": "omdb",
            "fetched_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        }

        # æ•´ç†æ’ˆå›çš„è³‡æ–™
        omdb_rating_data.append(
            {
                "title": omdb_crawler_data.get("Title"),
                "year": omdb_crawler_data.get("Year"),
                "imdb_id": omdb_crawler_data.get("imdbID"),
                "imdb_rating": omdb_crawler_data.get("imdbRating"),
                "imdb_votes": omdb_crawler_data.get("imdbVotes"),
                "metascore": omdb_crawler_data.get("Metascore"),
                "ratings": omdb_crawler_data.get("Ratings"),
                "crawl_note": crawl_note,
            }
        )
        print(f"âœ”ï¸ å·²å–å¾—è³‡æ–™ï¼š{atmovies_title_zh}")
        time.sleep(1)  # é¿å… API éè¼‰

    # --------------------------------------------
    # Step 6ï¼šè¼¸å‡ºçµæœ
    # --------------------------------------------
    fileName = f"rating_{WEEK_LABEL}.json"

    # è¼¸å‡ºæˆåŠŸè³‡æ–™
    save_json(omdb_rating_data, OUTPUT_DIR, fileName, "<æˆåŠŸè³‡æ–™>")
    print(
        f"""\n
ğŸ‰ IMDb è©•åˆ†è³‡æ–™å·²å®Œæˆ
ğŸ“‚ é¦–è¼ªé›»å½±ç­†æ•¸ï¼š{len(first_run_df)}
ğŸ“‚ æˆåŠŸè³‡æ–™ï¼Œå…± {len(omdb_rating_data)} ç­†
ğŸ“‚ ç•°å¸¸è³‡æ–™ï¼Œå…± {len(errors_record)} ç­† """
    )

    # è¼¸å‡ºéŒ¯èª¤ç´€éŒ„
    create_error_record(errors_record)


# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€” ä¸»ç¨‹å¼åŸ·è¡Œå…¥å£ â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
if __name__ == "__main__":
    fetch_weekly_ratings()
