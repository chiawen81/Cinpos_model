"""
OMDb æ•´åˆçˆ¬èŸ²ï¼ˆInfo + Ratingï¼‰
-------------------------------------------------
ğŸ¯ ç›®æ¨™ï¼š
    ä»¥æ”¿åºœã€Šå–®éƒ¨é›»å½±ç¥¨æˆ¿åŸå§‹è³‡æ–™ã€‹ç‚ºè¼¸å…¥ï¼Œ
    æ’ˆå– OMDb çš„é›»å½±è³‡è¨Šèˆ‡ IMDb è©•åˆ†ï¼Œä¸¦æ•´åˆç‚ºå–®ä¸€ JSONã€‚

ğŸ“‚ è³‡æ–™æµï¼š
    input  : data/raw/boxoffice_permovie/<year>/<week>/
    output : data/raw/omdb/<year>/<week>/<gov_id>_<title_zh>_<imdb_id>.json
    error  : data/raw/omdb/error/error_<timestamp>.json

ğŸ“¦ è¼”åŠ©è³‡æ–™ï¼š
    - .env â†’ OMDB_API_KEY
    - data/manual_fix/fix_omdb_mapping.json ï¼ˆäººå·¥å°ç…§è¡¨ï¼‰
"""

# -------------------------------------------------------
# å¥—ä»¶åŒ¯å…¥
# -------------------------------------------------------
import os
import json
import time
import requests
from datetime import datetime
from urllib.parse import quote
from dotenv import load_dotenv
from tqdm import tqdm

# å…±ç”¨æ¨¡çµ„
from common.path_utils import (
    BOXOFFICE_PERMOVIE_RAW,
    OMDB_RAW,
    MANUAL_FIX_DIR,
)
from common.file_utils import ensure_dir, save_json, clean_filename, load_json
from common.date_utils import get_current_year_label, get_current_week_label


# -------------------------------------------------------
# å…¨åŸŸè¨­å®š
# -------------------------------------------------------
load_dotenv()
API_KEY = os.getenv("OMDB_API_KEY")

YEAR_LABEL = get_current_year_label()
WEEK_LABEL = get_current_week_label()

FIX_MAPPING_FILE = os.path.join(MANUAL_FIX_DIR, "fix_omdb_mapping.json")
manual_mapping = (
    json.load(open(FIX_MAPPING_FILE, "r", encoding="utf-8"))
    if os.path.exists(FIX_MAPPING_FILE)
    else []
)

error_records = []  # å„²å­˜ç•¥éèˆ‡ç•°å¸¸è³‡æ–™
SLEEP_INTERVAL = 1.2

# è³‡æ–™å¤¾ç›®éŒ„
INPUT_DIR = os.path.join(BOXOFFICE_PERMOVIE_RAW, YEAR_LABEL, WEEK_LABEL)
OUTPUT_DIR = os.path.join(OMDB_RAW, YEAR_LABEL, WEEK_LABEL)
ERROR_DIR = os.path.join(OMDB_RAW, "error")
# ç¢ºå®šè³‡æ–™å¤¾å­˜åœ¨
ensure_dir(OUTPUT_DIR)
ensure_dir(ERROR_DIR)


# -------------------------------------------------------
# å·¥å…·å‡½å¼
# -------------------------------------------------------
def save_error(error_type: str, reason: str, extra: dict = None):
    """çµ±ä¸€è¨˜éŒ„éŒ¯èª¤è¨Šæ¯"""
    record = {
        "type": error_type,
        "reason": reason,
        "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
    }
    if extra:
        record.update(extra)
    error_records.append(record)


def find_manual_imdb_id(gov_id: str) -> dict:
    """å¾äººå·¥å°ç…§è¡¨ä¸­å°‹æ‰¾ IMDb ID"""
    for item in manual_mapping:
        if str(item.get("gov_id")) == str(gov_id):
            return {"imdb_id": item.get("imdb_id"), "is_matched": True}
    return {"imdb_id": "", "is_matched": False}


def fetch_omdb(api_param: str, by: str = "title") -> dict:
    """å‘¼å« OMDb APIï¼ˆå¯ç”¨ title æˆ– id æŸ¥è©¢ï¼‰"""
    if by == "title":
        url = f"https://www.omdbapi.com/?apikey={API_KEY}&t={quote(api_param)}&plot=full"
    else:
        url = f"https://www.omdbapi.com/?apikey={API_KEY}&i={api_param}&plot=full"

    try:
        response = requests.get(url, timeout=10)
        response.raise_for_status()
        return response.json()
    except requests.exceptions.RequestException as e:
        return {"Response": "False", "Error": str(e)}


# -------------------------------------------------------
# ä¸»æµç¨‹
# -------------------------------------------------------
def crawl_omdb_for_week():
    """ä¸»å‡½å¼ï¼šä»¥æœ¬é€±ç¥¨æˆ¿é›»å½±ç‚ºåŸºæº–æ’ˆå– OMDb è³‡æ–™"""
    if not API_KEY:
        raise ValueError("âŒ æ‰¾ä¸åˆ° OMDB_API_KEYï¼Œè«‹ç¢ºèª .env æ˜¯å¦è¨­å®š")

    if not os.path.exists(INPUT_DIR):
        print(f"âš ï¸ æ‰¾ä¸åˆ°æœ¬é€±ç¥¨æˆ¿åŸå§‹è³‡æ–™å¤¾ï¼š{INPUT_DIR}")
        return

    json_files = [f for f in os.listdir(INPUT_DIR) if f.endswith(".json")]
    if not json_files:
        print(f"âš ï¸ æ²’æœ‰å¯ç”¨çš„ JSON æª”æ¡ˆï¼š{INPUT_DIR}")
        return

    print(f"ğŸ¬ ç™¼ç¾ {len(json_files)} éƒ¨é›»å½±å¾…çˆ¬å– OMDb è³‡æ–™")
    print(f"ğŸ“… é€±æœŸï¼š{WEEK_LABEL}\n")

    success_count = 0

    # 2ï¸âƒ£ é€ä¸€è™•ç†é›»å½±
    for file_name in tqdm(json_files, desc="OMDb Fetching", ncols=90):
        file_path = os.path.join(INPUT_DIR, file_name)

        try:
            raw_json = load_json(file_path)
            movie_data = raw_json.get("data", {})
            # -------------------------------------------------
            # å‰ç½®æª¢æŸ¥
            # -------------------------------------------------
            # ç¢ºèª data/raw/boxoffice_permovie/<year>/<week> æœ‰è³‡æ–™
            if not movie_data:
                save_error("empty_json", "ç„¡æœ‰æ•ˆå…§å®¹", {"file": file_name})
                print(f"âš ï¸ ç„¡æœ‰æ•ˆå…§å®¹ï¼š{file_name}")
                continue

            gov_id = str(movie_data.get("movieId") or "")
            gov_title_zh = clean_filename(str(movie_data.get("name") or ""))
            gov_title_en = str(movie_data.get("originalName") or "").strip()
            gov_file_info = {
                "gov_id": gov_id,
                "gov_title_zh": gov_title_zh,
                "gov_title_en": gov_title_en,
            }

            # ä¸çˆ¬ç„¡è‹±æ–‡ç‰‡åçš„é›»å½±
            if not gov_title_en:
                save_error(
                    "missing_en_title",
                    "ç„¡è‹±æ–‡ç‰‡å",
                    gov_file_info,
                )
                continue

            # -------------------------------------------------
            # é–‹å§‹çˆ¬å–è³‡æ–™
            # -------------------------------------------------
            # å„ªå…ˆç”¨äººå·¥ mapping
            mapping = find_manual_imdb_id(gov_id)
            imdb_id = mapping["imdb_id"]

            if imdb_id:
                # ç¬¬äºŒæ¬¡çˆ¬å–ï¼šå·²åŠ å…¥è‡³äººå·¥å°ç…§è¡¨ï¼Œç›´æ¥ç”¨ IMDb ID æŸ¥
                data = fetch_omdb(imdb_id, by="id")
                fetch_mode = "by_imdb_id_from_manual_fix"
            else:
                if mapping["is_matched"] == True:
                    save_error(
                        "omdbæŸ¥ä¸åˆ°è³‡æ–™(å·²è¨˜éŒ„åœ¨äººå·¥å°ç…§è¡¨)", "OMDb æŸ¥ä¸åˆ°è³‡æ–™", gov_file_info
                    )
                    continue
                else:
                    # ç¬¬ä¸€æ¬¡çˆ¬å–ï¼šä»¥è‹±æ–‡ç‰‡åæŸ¥è©¢
                    data = fetch_omdb(gov_title_en, by="title")
                    fetch_mode = "by_title_from_gov"

                    if data.get("Response") == "False":
                        save_error("Movie not found", "OMDb æŸ¥ä¸åˆ°è³‡æ–™", gov_file_info)
                        continue

            # -------------------------------------------------
            # å„²å­˜æˆåŠŸçµæœ
            # -------------------------------------------------
            if data.get("Response") == "True" and data.get("imdbID"):
                imdb_id = data["imdbID"]
                rating = data.get("imdbRating", "")
                votes = data.get("imdbVotes", "")

                print(
                    f"[æˆåŠŸ] {gov_title_zh} ({gov_title_en}) - IMDb {rating} ({votes}) [{fetch_mode}]"
                )

                # åŠ ä¸Šçˆ¬å–è³‡è¨Šå€å¡Š
                data["crawl_note"] = {
                    "gov_id": gov_id,
                    "gov_title_zh": gov_title_zh,
                    "gov_title_en": gov_title_en,
                    "imdb_id": imdb_id,
                    "source": "omdb",
                    "fetch_mode": fetch_mode,
                    "week_label": WEEK_LABEL,
                    "year_label": YEAR_LABEL,
                    "fetched_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                }

                # å„²å­˜æª”æ¡ˆ
                file_name_out = f"{gov_id}_{gov_title_zh}_{imdb_id}.json"
                save_json(data, OUTPUT_DIR, file_name_out)
                success_count += 1

            else:
                save_error("api_error", data.get("Error", "OMDb å›å‚³å¤±æ•—"), gov_file_info)
                print(f"[å¤±æ•—] {gov_title_zh} ({gov_title_en}) - {data.get('Error', 'æœªçŸ¥éŒ¯èª¤')}")

        except Exception as e:
            save_error("exception", str(e), {"file": file_name})
            print(f"[ä¾‹å¤–] {file_name} - {e}")
            continue

        time.sleep(SLEEP_INTERVAL)

    # 4ï¸âƒ£ çµ±è¨ˆè¼¸å‡º
    print("\n==============================")
    print("ğŸ‰ æœ¬é€± OMDb è³‡æ–™æŠ“å–å®Œæˆ")
    print(f"ğŸ“… é€±æœŸï¼š{WEEK_LABEL}")
    print(f"âœ… æˆåŠŸï¼š{success_count} ç­†")
    print(f"âŒ å¤±æ•—ï¼š{len(error_records)} ç­†")
    print(f"ğŸ“ è¼¸å‡ºè³‡æ–™å¤¾ï¼š{OUTPUT_DIR}")
    print("==============================\n")

    # 5ï¸âƒ£ è¼¸å‡ºéŒ¯èª¤ç´€éŒ„
    if error_records:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        save_json(error_records, ERROR_DIR, f"error_{timestamp}.json")
        print(f"âš ï¸ å·²è¼¸å‡ºéŒ¯èª¤ç´€éŒ„ {len(error_records)} ç­† â†’ error_{timestamp}.json")
    else:
        print("âœ… ç„¡ç•°å¸¸ç´€éŒ„")


# -------------------------------------------------------
# ä¸»ç¨‹å¼åŸ·è¡Œå…¥å£
# -------------------------------------------------------
if __name__ == "__main__":
    crawl_omdb_for_week()
