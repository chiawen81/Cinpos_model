"""
IMDb / OMDb è©•åˆ†è³‡æ–™çˆ¬å–
----------------------------------
ç›®æ¨™ï¼š
    æ’ˆå–ç•¶é€±é¦–è¼ªé›»å½±çš„ IMDb / OMDb è©•åˆ†è³‡æ–™

æ­¥é©Ÿï¼š
    step1. è®€å–ç•¶é€±ã€Šé¦–è¼ªé›»å½±åå–®ã€‹
    step2. æ‰¿ä¸Šï¼Œæ ¹æ“š atmovies_id æ‰¾å‡ºå°æ‡‰ imdb_id
    step3. å‘¼å« OMDb APIï¼Œå–å¾— imdbRatingã€imdbVotesã€Metascoreã€Ratings ç­‰è©•åˆ†è³‡æ–™

çˆ¬èŸ²ç›®æ¨™APIï¼š
   https://www.omdbapi.com/?apikey=<OMDB_API_KEY>6&i=<IMDB_ID>&plot=full

è¼¸å…¥ä¾†æºï¼š
    - å–å¾—ç•¶å‘¨é¦–è¼ªé›»å½±ï¼šdata/processed/firstRunFilm_list/<ç•¶å‘¨>/firstRun_<ç•¶å‘¨>.csv
    - å–å¾—æ¯éƒ¨é›»å½±å°æ‡‰çš„imdb IDï¼šdata/processed/movieInfo_omdb/movieInfo_omdb_<ä¸Šæ¬¡åŸ·è¡Œæ—¥æœŸ>.csv

è¼¸å‡ºï¼š
    - æˆåŠŸè³‡æ–™ï¼šdata/raw/rating_weekly/<ç•¶é€±>/rating_<ç•¶é€±>.json
    - éŒ¯èª¤ç´€éŒ„ï¼šdata/raw/rating_weekly/error/error_<timestamp>.json
"""
# -------------------------------------------------------
# å¥—ä»¶åŒ¯å…¥
# -------------------------------------------------------
import os
import json
import time
import requests
import pandas as pd
from datetime import datetime

# å…±ç”¨æ¨¡çµ„
from common.path_utils import RATING_WEEKLY_RAW, FIRSTRUN_PROCESSED, MOVIEINFO_OMDb_PROCESSED
from common.file_utils import ensure_dir
from common.date_utils import get_current_week_label


# -------------------------------------------------------
# å…¨åŸŸè¨­å®š
# -------------------------------------------------------
OMDB_API_KEY = os.getenv("OMDB_API_KEY") or "<YOUR_API_KEY>"
WEEK_LABEL = get_current_week_label()
OUTPUT_DIR = os.path.join(RATING_WEEKLY_RAW, WEEK_LABEL)
ERROR_DIR = os.path.join(RATING_WEEKLY_RAW, "error")
ensure_dir(OUTPUT_DIR)
ensure_dir(ERROR_DIR)


# -------------------------------------------------------
# å·¥å…·å‡½å¼(æª¢æŸ¥å¯æŠ½å…±ç”¨)
# -------------------------------------------------------
def fetch_omdb_rating(imdb_id: str) -> dict:
    """æ‰“ OMDb APIï¼Œå–å¾—é›»å½±è©•åˆ†è³‡æ–™"""
    url = f"https://www.omdbapi.com/?apikey={OMDB_API_KEY}&i={imdb_id}&plot=full"
    try:
        response = requests.get(url, timeout=10)
        data = response.json()
        if data.get("Response") == "False":
            return {"error": data.get("Error", "Movie not found")}
        return data
    except Exception as e:
        return {"error": str(e)}


def save_json(data: list, path: str):
    """å­˜æˆ JSON æª”"""
    ensure_dir(os.path.dirname(path))
    with open(path, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)


def log_error(errors: list):
    """è¼¸å‡ºéŒ¯èª¤ç´€éŒ„"""
    if not errors:
        return
    ts = datetime.now().strftime("%Y%m%d_%H%M%S")
    err_path = os.path.join(ERROR_DIR, f"error_{ts}.json")
    save_json(errors, err_path)
    print(f"âš ï¸ å·²è¼¸å‡ºéŒ¯èª¤ç´€éŒ„ï¼š{err_path}")


# ========= ä¸»ç¨‹å¼ =========
def fetch_weekly_ratings():
    print(f"ğŸ¬ é–‹å§‹æ’ˆå– IMDb / OMDb è©•åˆ†è³‡æ–™ï¼ˆé€±æ¬¡ï¼š{WEEK_LABEL}ï¼‰")

    # Step 1ï¸âƒ£ï¼šè®€å–ç•¶é€±é¦–è¼ªé›»å½±æ¸…å–®
    first_run_path = os.path.join(FIRSTRUN_PROCESSED, WEEK_LABEL, f"firstRun_{WEEK_LABEL}.csv")
    if not os.path.exists(first_run_path):
        print(f"âŒ æ‰¾ä¸åˆ°é¦–è¼ªé›»å½±æ¸…å–®ï¼š{first_run_path}")
        return

    first_run_df = pd.read_csv(first_run_path, encoding="utf-8")
    print(f"ğŸ“‚ é¦–è¼ªé›»å½±ç­†æ•¸ï¼š{len(first_run_df)}")

    # Step 2ï¸âƒ£ï¼šè®€å– OMDb è³‡æ–™ï¼ˆç”¨æ–¼å°ç…§ imdb_idï¼‰
    omdb_files = [f for f in os.listdir(MOVIEINFO_OMDb_PROCESSED) if f.endswith(".csv")]
    if not omdb_files:
        print(f"âŒ æ‰¾ä¸åˆ° OMDb å°ç…§è³‡æ–™ï¼š{MOVIEINFO_OMDb_PROCESSED}")
        return

    omdb_latest = max(omdb_files, key=lambda x: os.path.getmtime(os.path.join(MOVIEINFO_OMDb_PROCESSED, x)))
    omdb_path = os.path.join(MOVIEINFO_OMDb_PROCESSED, omdb_latest)
    omdb_df = pd.read_csv(omdb_path, encoding="utf-8")
    print(omdb_df)
    print("====================================\n")
    print(f"ğŸ” ä½¿ç”¨ OMDb å°ç…§è³‡æ–™ï¼š{omdb_latest}")
    print("====================================\n")
    print(first_run_df)

    # åˆä½µ imdb_id
    merged = first_run_df.merge(
        omdb_df[["gov_title_zh", "atmovies_id", "imdb_id"]],
        on="atmovies_id",
        how="left"
    )

    missing = merged[merged["imdb_id"].isna()]
    if not missing.empty:
        print(f"âš ï¸ æ‰¾ä¸åˆ° IMDb ID çš„é›»å½±ï¼š{len(missing)} ç­†")
        print("====================================")
        print(merged)
        for _, row in missing.iterrows():
            print(f"  - {row['atmovies_title_zh']} ({row['atmovies_id']})")

    # Step 3ï¸âƒ£ï¼šæ’ˆå– IMDb è©•åˆ†è³‡æ–™
    results = []
    errors = []

    for _, row in merged.iterrows():
        atmovies_id = row["atmovies_id"]
        imdb_id = row["imdb_id"]
        gov_title_zh = row.get("gov_title_zh", "")
        atmovies_title_zh = row.get("atmovies_title_zh", "")

        if not imdb_id or imdb_id == "N/A":
            errors.append({
                "atmovies_id": atmovies_id,
                "atmovies_title_zh": atmovies_title_zh,
                "error": "ç„¡ IMDb ID å°æ‡‰"
            })
            continue

        data = fetch_omdb_rating(imdb_id)
        if "error" in data:
            errors.append({
                "atmovies_id": atmovies_id,
                "imdb_id": imdb_id,
                "gov_title_zh": gov_title_zh,
                "error": data["error"]
            })
            continue

        result = {
            "atmovies_id": atmovies_id,
            "gov_title_zh": gov_title_zh,
            "title": data.get("Title"),
            "year": data.get("Year"),
            "imdb_id": data.get("imdbID"),
            "imdb_rating": data.get("imdbRating"),
            "imdb_votes": data.get("imdbVotes"),
            "metascore": data.get("Metascore"),
            "ratings": data.get("Ratings"),
            "fetched_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        }

        results.append(result)
        print(f"âœ… {atmovies_title_zh} ({imdb_id}) - IMDb {result['imdb_rating']}")
        time.sleep(1)  # é¿å… API éè¼‰

    # Step 4ï¸âƒ£ï¼šè¼¸å‡ºçµæœ
    output_path = os.path.join(OUTPUT_DIR, f"rating_{WEEK_LABEL}.json")
    save_json(results, output_path)
    print(f"\nğŸ‰ IMDb è©•åˆ†è³‡æ–™å·²å®Œæˆï¼Œå…± {len(results)} ç­†\nğŸ‘‰ å„²å­˜ä½ç½®ï¼š{output_path}")

    # Step 5ï¸âƒ£ï¼šè¼¸å‡ºéŒ¯èª¤ç´€éŒ„
    log_error(errors)


if __name__ == "__main__":
    fetch_weekly_ratings()