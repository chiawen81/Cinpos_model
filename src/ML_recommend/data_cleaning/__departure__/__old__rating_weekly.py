"""
IMDb / OMDb è©•åˆ†è³‡æ–™æ¸…æ´—
----------------------------------
ç›®æ¨™ï¼š
    å°‡ rating_weekly.py çˆ¬å–å¾Œçš„ JSON æ¸…æ´—æˆå¯åˆ†æç”¨çš„ CSVã€‚
    åŒæ™‚è¼¸å‡ºå…©ä»½ç‰ˆæœ¬ï¼š
        1. _cleanedï¼šåƒ… IMDb è³‡æ–™
        2. _fullï¼šåŒ…å« IMDb + Rotten Tomatoes + Metacritic

è¼¸å…¥ï¼š
    data/raw/rating_weekly/<ç•¶å‘¨>/rating_<ç•¶å‘¨>.json

è¼¸å‡ºï¼š
    data/processed/rating_weekly__<ç•¶å‘¨>_cleaned.csv
    data/processed/rating_weekly__<ç•¶å‘¨>_full.csv
"""

# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€” å¥—ä»¶åŒ¯å…¥ â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
import os
import json
import pandas as pd
# å…±ç”¨æ¨¡çµ„
from common.file_utils import save_csv
from common.date_utils import get_week_label
from common.path_utils import RATING_WEEKLY_PROCESSED


# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€” å±•å¹³è¼”åŠ©å‡½å¼ â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
def extract_ratings(ratings_list):
    """å¾ ratings list ä¸­æå– IMDbã€Rottenã€Metacritic è©•åˆ†"""
    if not isinstance(ratings_list, list):
        return pd.Series([None, None, None])
    imdb, rotten, meta = None, None, None
    for r in ratings_list:
        src = r.get("Source", "").lower()
        val = r.get("Value")
        if "internet movie" in src:
            imdb = val
        elif "rotten" in src:
            rotten = val
        elif "metacritic" in src:
            meta = val
    return pd.Series([imdb, rotten, meta])


def extract_note(note_dict):
    """æå– crawl_note ä¸­çš„ gov_idã€atmovies_idã€atmovies_title_zh"""
    if not isinstance(note_dict, dict):
        return pd.Series([None, None, None])
    return pd.Series([
        note_dict.get("gov_id"),
        note_dict.get("atmovies_id"),
        note_dict.get("atmovies_title_zh"),
    ])


# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€” ä¸»è¦æ¸…æ´—å‡½å¼ â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
def clean_rating_weekly(raw_folder: str, week_label: str):
    """æ¸…æ´— IMDb / OMDb è©•åˆ†è³‡æ–™"""
    raw_path = os.path.join(raw_folder, f"rating_{week_label}.json")
    print("raw_path", raw_path)
    if not os.path.exists(raw_path):
        print(f"âš ï¸ æ‰¾ä¸åˆ°ä¾†æºæª”æ¡ˆï¼š{raw_path}")
        return

    # è®€å– JSON
    with open(raw_path, "r", encoding="utf-8") as f:
        data = json.load(f)

    total_count = len(data)
    print(f"ğŸ“¦ æœ¬æ¬¡é è¨ˆæ¸…æ´—ç­†æ•¸ï¼š{total_count}")

    # è½‰æˆ DataFrame
    df = pd.DataFrame(data)

    # å±•å¹³æ¬„ä½
    df[["rating_imdb_src", "rating_rotten_src", "rating_meta_src"]] = df["ratings"].apply(extract_ratings)
    df[["gov_id", "atmovies_id", "atmovies_title_zh"]] = df["crawl_note"].apply(extract_note)

    # æ•¸å€¼è½‰æ›
    if "imdbRating" in df.columns:
        df["imdbRating"] = pd.to_numeric(df["imdbRating"], errors="coerce")
    if "imdbVotes" in df.columns:
        df["imdbVotes"] = (
            df["imdbVotes"].astype(str).str.replace(",", "").replace("N/A", None)
        )
        df["imdbVotes"] = pd.to_numeric(df["imdbVotes"], errors="coerce")

    # å»é‡
    before_drop = len(df)
    df.drop_duplicates(subset=["imdb_id"], inplace=True)
    after_drop = len(df)
    dropped = before_drop - after_drop

    # çµ±ä¸€æ¬„ä½
    df.rename(
        columns={
            "title": "omdb_title",
            "imdbRating": "imdb_rating",
            "imdbVotes": "imdb_votes",
            "rating_rotten_src": "tomatoes_rating",
            "rating_meta_src": "metacritic_rating",
        },
        inplace=True,
    )

    # æ¬„ä½é †åº
    col_order = [
        "imdb_id",
        "atmovies_title_zh",
        "omdb_title",
        "imdb_votes",
        "imdb_rating",
        "tomatoes_rating",
        "metacritic_rating",
        "atmovies_id",
        "gov_id",
    ]

    # è£œé½Šç¼ºæ¬„ä½ï¼ˆé¿å…éƒ¨åˆ†ç¼ºå¤±å ±éŒ¯ï¼‰
    for col in col_order:
        if col not in df.columns:
            df[col] = None
    df = df[col_order]

    # è¼¸å‡ºå…©ç‰ˆæœ¬
    cleaned_df = df[["imdb_id", "atmovies_title_zh", "omdb_title", "imdb_votes", "imdb_rating", "atmovies_id", "gov_id"]]
    cleaned_name = f"rating_weekly__{week_label}_cleaned.csv"
    full_name = f"rating_weekly__{week_label}_full.csv"

    save_csv(cleaned_df, RATING_WEEKLY_PROCESSED, cleaned_name)
    save_csv(df, RATING_WEEKLY_PROCESSED, full_name)

    # çµ±è¨ˆè¼¸å‡º
    success_count = len(df)
    fail_count = total_count - success_count
    print(f"âœ… æ¸…æ´—å®Œæˆï¼š")
    print(f"ã€€â”œâ”€ åŸå§‹ç­†æ•¸ï¼š{total_count}")
    print(f"ã€€â”œâ”€ å»é™¤é‡è¤‡ï¼š{dropped} ç­†")
    print(f"ã€€â”œâ”€ æˆåŠŸæ¸…æ´—ï¼š{success_count} ç­†")
    print(f"ã€€â””â”€ æ¸…æ´—å¤±æ•—ï¼š{fail_count} ç­† (å¯èƒ½ç‚ºç¼º imdb_id æˆ–æ ¼å¼éŒ¯èª¤)")
    print(f"\nğŸ“ å·²è¼¸å‡ºï¼š\n â”œâ”€ {cleaned_name}\n â””â”€ {full_name}")


# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€” ä¸»ç¨‹å¼åŸ·è¡Œå…¥å£ â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
if __name__ == "__main__":
    week_label = get_week_label()
    raw_folder = f"data/raw/rating_weekly/{week_label}"
    clean_rating_weekly(raw_folder, week_label)
