"""
OMDb è³‡æ–™æ¸…æ´—æ¨¡çµ„
-------------------------------------------------
ğŸ¯ ç›®æ¨™ï¼š
    å°‡ data/raw/omdb/<year>/<week> ä¸‹çš„åŸå§‹ JSON
    è½‰æ›ç‚ºçµæ§‹åŒ– CSVï¼ˆå–®æ”¯ã€é€±å½™æ•´ã€å…¨åŸŸåˆä½µï¼‰ã€‚

ğŸ“‚ è³‡æ–™æµï¼š
    input  : data/raw/omdb/<year>/<week>/
    output :
        - data/processed/movieInfo_omdb/<year>/<week>/<gov_id>_<title_zh>_<imdb_id>.csv
        - data/processed/movieInfo_omdb/<year>/<week>/omdb_<å‘¨æ¬¡>.csv
        - data/processed/movieInfo_omdb/combined/omdb_all.csv
"""

# -------------------------------------------------------
# å¥—ä»¶åŒ¯å…¥
# -------------------------------------------------------
import os
import json
import pandas as pd
from datetime import datetime

# å…±ç”¨æ¨¡çµ„
from common.path_utils import OMDB_RAW, MOVIEINFO_OMDB_PROCESSED
from common.file_utils import ensure_dir, save_csv, load_json, clean_filename
from common.date_utils import get_current_year_label, get_current_week_label


# -------------------------------------------------------
# å…¨åŸŸè¨­å®š
# -------------------------------------------------------
YEAR_LABEL = get_current_year_label()
WEEK_LABEL = get_current_week_label()

RAW_DIR = os.path.join(OMDB_RAW, YEAR_LABEL, WEEK_LABEL)
PROCESSED_DIR = os.path.join(MOVIEINFO_OMDB_PROCESSED, YEAR_LABEL, WEEK_LABEL)
COMBINED_DIR = os.path.join(MOVIEINFO_OMDB_PROCESSED, "combined")

ensure_dir(PROCESSED_DIR)
ensure_dir(COMBINED_DIR)


# -------------------------------------------------------
# è¼”åŠ©å‡½å¼
# -------------------------------------------------------
def extract_ratings(data: dict):
    """æ‹†è§£ Ratings æ¬„ä½æˆ imdb/tomatoes/metacritic ä¸‰æ¬„"""
    imdb_rating = ""
    tomatoes_rating = ""
    metacritic_rating = ""

    ratings = data.get("Ratings", [])
    for r in ratings:
        src = r.get("Source", "")
        val = r.get("Value", "")
        if "Internet Movie Database" in src:
            imdb_rating = val
        elif "Rotten Tomatoes" in src:
            tomatoes_rating = val
        elif "Metacritic" in src:
            metacritic_rating = val

    return imdb_rating, tomatoes_rating, metacritic_rating


def flatten_omdb_json(data: dict) -> dict:
    """å°‡å–®æ”¯ OMDb JSON æ”¤å¹³æˆçµæ§‹åŒ–å­—å…¸"""
    note = data.get("crawl_note", {})

    imdb_rating, tomatoes_rating, metacritic_rating = extract_ratings(data)

    return {
        "gov_id": note.get("gov_id", ""),
        "gov_title_zh": note.get("gov_title_zh", ""),
        "gov_title_en": note.get("gov_title_en", ""),
        "imdb_id": data.get("imdbID", ""),
        "omdb_title_en": data.get("Title", ""),
        "year": data.get("Year", ""),
        "runtime": data.get("Runtime", ""),
        "genre": data.get("Genre", ""),
        "language": data.get("Language", ""),
        "country": data.get("Country", ""),
        "director": data.get("Director", ""),
        "writer": data.get("Writer", ""),
        "actors": data.get("Actors", ""),
        "plot": data.get("Plot", ""),
        "awards": data.get("Awards", ""),
        "poster": data.get("Poster", ""),
        "imdb_rating": imdb_rating,
        "tomatoes_rating": tomatoes_rating,
        "metacritic_rating": metacritic_rating,
        "source": note.get("source", "omdb"),
        "fetched_at": note.get("fetched_at", datetime.now().strftime("%Y-%m-%d %H:%M:%S")),
    }


def combine_weekly_csv(output_dir: str, combined_dir: str, year_label: str, week_label: str):
    """å°‡ç•¶é€±æ‰€æœ‰ CSV åˆä½µæˆä¸€æ”¯ weekly combined"""
    all_csv = [os.path.join(output_dir, f) for f in os.listdir(output_dir) if f.endswith(".csv")]
    if not all_csv:
        print("âš ï¸ ç„¡å¯åˆä½µçš„ CSVã€‚")
        return None

    dfs = [pd.read_csv(f, encoding="utf-8") for f in all_csv]
    combined_df = pd.concat(dfs, ignore_index=True)

    weekly_filename = f"omdb_combined_{week_label}.csv"
    weekly_path = os.path.join(output_dir, weekly_filename)
    save_csv(combined_df, output_dir, weekly_filename)
    print(f"ğŸ“ å·²ç”¢ç”Ÿé€±å½™æ•´ï¼š{weekly_path}")

    return combined_df


def update_all_combined(combined_dir: str, new_df: pd.DataFrame):
    """æ›´æ–°å…¨åŸŸåˆä½µæª” (omdb_all_YYYY-MM-DD.csv)ï¼Œè‡ªå‹•æ’é‡"""
    today_label = datetime.now().strftime("%Y-%m-%d")
    all_filename = f"omdb_all_{today_label}.csv"
    all_path = os.path.join(combined_dir, all_filename)

    if os.path.exists(all_path):
        old_df = pd.read_csv(all_path, encoding="utf-8")
        merged = pd.concat([old_df, new_df], ignore_index=True)
        merged.drop_duplicates(subset=["imdb_id"], inplace=True)
    else:
        merged = new_df

    save_csv(merged, combined_dir, all_filename)
    print(f"ğŸ“ å·²æ›´æ–°å…¨åŸŸåˆä½µï¼š{all_path}ï¼ˆå…± {len(merged)} ç­†ï¼‰")


# -------------------------------------------------------
# ä¸»æ¸…æ´—æµç¨‹
# -------------------------------------------------------
def clean_omdb_data():
    if not os.path.exists(RAW_DIR):
        print(f"âš ï¸ æ‰¾ä¸åˆ°åŸå§‹è³‡æ–™å¤¾ï¼š{RAW_DIR}")
        return

    json_files = [f for f in os.listdir(RAW_DIR) if f.endswith(".json")]
    if not json_files:
        print("âš ï¸ ç„¡å¯æ¸…æ´—çš„ JSON æª”æ¡ˆã€‚")
        return

    print(f"ğŸš€ é–‹å§‹æ¸…æ´— OMDb è³‡æ–™ï¼Œå…± {len(json_files)} éƒ¨é›»å½±")

    processed_count = 0
    for file_name in json_files:
        file_path = os.path.join(RAW_DIR, file_name)
        data = load_json(file_path)
        if not data:
            print(f"âš ï¸ ç„¡æ³•è®€å–æˆ–å…§å®¹ç©ºç™½ï¼š{file_name}")
            continue

        flat_data = flatten_omdb_json(data)
        safe_title = clean_filename(flat_data["gov_title_zh"] or "unknown")
        csv_name = f"{flat_data['gov_id']}_{safe_title}_{flat_data['imdb_id']}.csv"

        df = pd.DataFrame([flat_data])
        save_csv(df, PROCESSED_DIR, csv_name)
        processed_count += 1

    print(f"âœ… æ¸…æ´—å®Œæˆï¼Œå…±è™•ç† {processed_count} ç­†è³‡æ–™ã€‚")

    # åˆä½µç•¶é€±è³‡æ–™
    weekly_df = combine_weekly_csv(PROCESSED_DIR, COMBINED_DIR, YEAR_LABEL, WEEK_LABEL)
    if weekly_df is not None:
        update_all_combined(COMBINED_DIR, weekly_df)

    print("ğŸ‰ OMDb æ¸…æ´—æµç¨‹å®Œæˆï¼")


# -------------------------------------------------------
# ä¸»ç¨‹å¼åŸ·è¡Œå€
# -------------------------------------------------------
if __name__ == "__main__":
    clean_omdb_data()
