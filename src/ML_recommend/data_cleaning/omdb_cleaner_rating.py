"""
OMDb è©•åˆ†è³‡æ–™æ¸…æ´—æ¨¡çµ„
-------------------------------------------------
ğŸ¯ ç›®æ¨™ï¼š
    è®€å– data/raw/omdb/<year>/<week>/ ä¸‹çš„ JSONï¼Œ
    æå–è©•åˆ†ç›¸é—œæ¬„ä½ï¼ˆIMDb / Rotten / Metacriticï¼‰ï¼Œ
    è¼¸å‡ºé€éƒ¨é›»å½±çš„æ­·å²è©•åˆ†ç´€éŒ„ã€‚

ğŸ“‚ è³‡æ–™æµï¼š
    input  : data/raw/omdb/<year>/<week>/
    output : data/processed/rating_omdb/<gov_id>_<title_zh>_<imdb_id>.csv
"""

# -------------------------------------------------------
# å¥—ä»¶åŒ¯å…¥
# -------------------------------------------------------
import os
import pandas as pd
from datetime import datetime

# å…±ç”¨æ¨¡çµ„
from common.path_utils import OMDB_RAW, RATING_OMDB_PROCESSED
from common.file_utils import ensure_dir, load_json, save_csv, clean_filename
from common.date_utils import get_current_year_label, get_current_week_label


# -------------------------------------------------------
# å…¨åŸŸè¨­å®š
# -------------------------------------------------------
YEAR_LABEL = get_current_year_label()
WEEK_LABEL = get_current_week_label()

RAW_DIR = os.path.join(OMDB_RAW, YEAR_LABEL, WEEK_LABEL)
RATING_PROCESSED_DIR = RATING_OMDB_PROCESSED

ensure_dir(RATING_PROCESSED_DIR)


# -------------------------------------------------------
# è¼”åŠ©å‡½å¼
# -------------------------------------------------------
def extract_ratings(data: dict):
    """æ‹†è§£ Ratings æ¬„ä½æˆ imdb/tomatoes/metacritic ä¸‰æ¬„"""
    imdb_rating = ""
    tomatoes_rating = ""
    metacritic_rating = ""

    ratings = data.get("Ratings", [])
    for r in ratings:
        src = r.get("Source", "")
        val = r.get("Value", "")
        if "Internet Movie Database" in src:
            imdb_rating = val
        elif "Rotten Tomatoes" in src:
            tomatoes_rating = val
        elif "Metacritic" in src:
            metacritic_rating = val

    return imdb_rating, tomatoes_rating, metacritic_rating


def build_rating_row(data: dict) -> dict:
    """å¾å–®æ”¯ OMDb JSON æå–è©•åˆ†è³‡æ–™"""
    note = data.get("crawl_note", {})
    imdb_rating, tomatoes_rating, metacritic_rating = extract_ratings(data)

    # --- æ˜ç¢ºå€åˆ†å…©å€‹æ™‚é–“ä¾†æº ---
    crawl_date = note.get("fetched_at", "")  # çˆ¬èŸ²æ’ˆè³‡æ–™çš„æ™‚é–“
    update_at = datetime.now().strftime("%Y/%m/%d %H:%M")  # æ¸…æ´—å¯«å…¥æ™‚é–“

    return {
        "gov_id": note.get("gov_id", ""),
        "imdb_id": note.get("imdb_id", ""),
        "week_label": note.get("week_label", ""),
        "crawl_date": crawl_date,
        "imdb_rating": imdb_rating,
        "tomatoes_rating": tomatoes_rating,
        "metacritic_rating": metacritic_rating,
        "source": note.get("source", "omdb"),
        "update_at": update_at,
    }


def update_movie_rating_csv(row: dict, output_dir: str):
    """
    è‹¥è©²é›»å½±å·²æœ‰æ­·å²ç´€éŒ„ï¼Œå‰‡è¿½åŠ ä¸€è¡Œï¼›
    è‹¥ç„¡ï¼Œå‰‡å»ºç«‹æ–°æª”æ¡ˆã€‚
    """
    gov_id = row["gov_id"]
    imdb_id = row["imdb_id"]
    safe_title = clean_filename(row.get("gov_title_zh", ""))
    filename = f"{gov_id}_{safe_title}_{imdb_id}.csv"
    file_path = os.path.join(output_dir, filename)

    # è‹¥æª”æ¡ˆå·²å­˜åœ¨ï¼Œè¼‰å…¥å¾Œè¿½åŠ 
    if os.path.exists(file_path):
        old_df = pd.read_csv(file_path, encoding="utf-8")
        new_df = pd.DataFrame([row])
        merged_df = pd.concat([old_df, new_df], ignore_index=True)
    else:
        merged_df = pd.DataFrame([row])

    save_csv(merged_df, output_dir, filename)
    print(f"ğŸ“„ å·²æ›´æ–°è©•åˆ†ç´€éŒ„ï¼š{filename}ï¼ˆå…± {len(merged_df)} ç­†ï¼‰")


# -------------------------------------------------------
# ä¸»æ¸…æ´—æµç¨‹
# -------------------------------------------------------
def clean_omdb_ratings():
    """ä¸»æ¸…æ´—æµç¨‹"""
    if not os.path.exists(RAW_DIR):
        print(f"âš ï¸ æ‰¾ä¸åˆ°åŸå§‹è³‡æ–™å¤¾ï¼š{RAW_DIR}")
        return

    json_files = [f for f in os.listdir(RAW_DIR) if f.endswith(".json")]
    if not json_files:
        print("âš ï¸ ç„¡å¯æ¸…æ´—çš„ JSON æª”æ¡ˆã€‚")
        return

    print(f"ğŸš€ é–‹å§‹æ¸…æ´— OMDb è©•åˆ†è³‡æ–™ï¼Œå…± {len(json_files)} éƒ¨é›»å½±")

    processed_count = 0
    for file_name in json_files:
        file_path = os.path.join(RAW_DIR, file_name)
        data = load_json(file_path)
        if not data:
            print(f"âš ï¸ ç„¡æ³•è®€å–æˆ–å…§å®¹ç©ºç™½ï¼š{file_name}")
            continue

        note = data.get("crawl_note", {})
        row = build_rating_row(data)
        row["gov_title_zh"] = note.get("gov_title_zh", "")

        update_movie_rating_csv(row, RATING_PROCESSED_DIR)
        processed_count += 1

    print(f"âœ… æ¸…æ´—å®Œæˆï¼Œå…±è™•ç† {processed_count} ç­†è³‡æ–™ã€‚")
    print("ğŸ‰ OMDb è©•åˆ†æ¸…æ´—æµç¨‹å®Œæˆï¼")


# -------------------------------------------------------
# ä¸»ç¨‹å¼åŸ·è¡Œå€
# -------------------------------------------------------
if __name__ == "__main__":
    clean_omdb_ratings()
